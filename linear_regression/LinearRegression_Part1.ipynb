{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "691d7efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import fmean, pstdev\n",
    "import numpy as np\n",
    "rng = np.random.default_rng()\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd2539cd-a8bd-46e4-a9b9-eba42070f7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization_factors(xss):\n",
    "    return [(fmean(xs), pstdev(xs)) for xs in zip(*xss)]\n",
    "\n",
    "def normalized_input(xss, stats):\n",
    "    return [[(x - m) / s if s > 0 else 0 for x, (m, s) in zip(xs, stats)] for xs in xss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bafb39ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file with multiple attributes\n",
    "\n",
    "def read_input_file(filename):\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines[1:]:\n",
    "            line = [float(i.strip()) for i in line.split(',')]\n",
    "            x.append(line[:-1])\n",
    "            y.append(line[-1])\n",
    "            \n",
    "    # normalize input to have mean 0 and standard deviation 1\n",
    "    stats = normalization_factors(x)\n",
    "    x = normalized_input(x, stats)\n",
    "\n",
    "    return np.array(x), np.array(y), stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f8dd1df-ff64-490c-bf66-7e3aa5487923",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'demo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d24a019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attributes and output\n",
    "filename = f'datasets/{dataset}/train.txt'\n",
    "\n",
    "x, y, stats = read_input_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a3e6c2b2-ff5d-421e-bdf5-63fad043a8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm._instances.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b66d14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "# gradient descent for loss function\n",
    "\n",
    "def linear_regression(x, y):\n",
    "    w = rng.uniform(-1, 1, x.shape[1])\n",
    "    b = rng.uniform(-1, 1)\n",
    "    alpha = 0.01\n",
    "    n = x.shape[0]\n",
    "    \n",
    "    epochs = 100000 // n\n",
    "    for e in trange(epochs):\n",
    "        y_pred = w @ x.T + b\n",
    "        partial_w = x.T @ (y_pred - y) / n\n",
    "        partial_b = np.sum(y_pred - y) / n\n",
    "        w -= alpha * partial_w\n",
    "        b -= alpha * partial_b\n",
    " \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "640254ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 5000/5000 [00:00<00:00, 10304.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# weights and bias\n",
    "w, b = linear_regression(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a89eca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test file\n",
    "\n",
    "def read_test_file(test_file, stats):\n",
    "    t = []\n",
    "    \n",
    "    with open(test_file) as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines[1:]:\n",
    "            line = [float(i.strip()) for i in line.split(',')]\n",
    "            t.append(line)\n",
    "            \n",
    "    return np.array(normalized_input(t, stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74623d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f'datasets/{dataset}/test.txt'\n",
    "t = read_test_file(filename, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "163b2b7f-6cc0-473b-8b0e-e418e746600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [str(i) for i in np.dot(t, w) + b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8d65a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5256746948201834\n",
      "1.4259716265258837\n",
      "2.5513427911580093\n",
      "3.0014912570108594\n",
      "3.676713955790135\n",
      "0.7507489277466086\n",
      "1.2008973935994585\n",
      "2.3262685582315843\n",
      "2.7764170240844344\n",
      "3.9017881887165604\n"
     ]
    }
   ],
   "source": [
    "# use test file and write predicted values to new file\n",
    "with open(f'datasets/{dataset}/out.txt', 'w') as f:\n",
    "    print('\\n'.join(res))\n",
    "    f.write('\\n'.join(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c5eaad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1f8f0a-b81b-42c2-9166-de90ba2c3980",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs411]",
   "language": "python",
   "name": "conda-env-cs411-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
